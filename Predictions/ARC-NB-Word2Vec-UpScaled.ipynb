{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"ARC-NB-Word2Vec-UpScaled.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"o4WKnwbWwNZB","colab_type":"code","colab":{},"outputId":"ab1364ed-719f-451e-e372-e06a3dee04d1"},"source":["import os\n","import atexit\n","import sys\n","\n","import pyspark\n","from pyspark.context import SparkContext\n","from pyspark.sql import SQLContext\n","import findspark\n","from sparkhpc import sparkjob\n","\n","#Exit handler to clean up the Spark cluster if the script exits or crashes\n","def exitHandler(sj,sc):\n","    try:\n","        print('Trapped Exit cleaning up Spark Context')\n","        sc.stop()\n","    except:\n","        pass\n","    try:\n","        print('Trapped Exit cleaning up Spark Job')\n","        sj.stop()\n","    except:\n","        pass\n","\n","findspark.init()\n","\n","#Parameters for the Spark cluster\n","nodes=1\n","tasks_per_node=12\n","memory_per_task=1800 #1 gig per process, adjust accordingly\n","# Please estimate walltime carefully to keep unused Spark clusters from sitting \n","# idle so that others may use the resources.\n","walltime=\"24:00\" #1 hour\n","os.environ['SBATCH_PARTITION']='parallel' #Set the appropriate ARC partition\n","\n","sj = sparkjob.sparkjob(\n","     ncores=nodes*tasks_per_node,\n","     cores_per_executor=tasks_per_node,\n","     memory_per_core=memory_per_task,\n","     walltime=walltime\n","    )\n","\n","sj.wait_to_start()\n","sc = sj.start_spark()\n","\n","#Register the exit handler                                                                                                     \n","atexit.register(exitHandler,sj,sc)\n","\n","#You need this line if you want to use SparkSQL\n","sqlCtx=SQLContext(sc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:sparkhpc.sparkjob:Submitted batch job 2626365\n","\n","INFO:sparkhpc.sparkjob:Submitted cluster 1\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PQ3tDNyhwNZQ","colab_type":"code","colab":{},"outputId":"e5f03be8-ee36-4796-f50f-c173790f1486"},"source":["df = sqlCtx.read.csv('CleanedNews.csv/part-00000-e0c20413-d9a2-4ae3-bc41-a77b460c6a58-c000.csv',inferSchema=True)\n","df = df.withColumnRenamed('_c0','claim').withColumnRenamed('_c1','claimant').withColumnRenamed('_c2','articles').withColumnRenamed('_c3','label')\n","df.printSchema()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["root\n"," |-- claim: string (nullable = true)\n"," |-- claimant: string (nullable = true)\n"," |-- articles: string (nullable = true)\n"," |-- label: integer (nullable = true)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-JcHyHOGwNZZ","colab_type":"code","colab":{},"outputId":"e2856b2d-0f4f-4c17-c380-8d1658ed146b"},"source":["counts = df.select('label').groupBy('label').count().orderBy('count').collect()\n","counts"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(label=2, count=1696), Row(label=1, count=6451), Row(label=0, count=7408)]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"zuNyxb-cwNZf","colab_type":"code","colab":{}},"source":["lowestLabel,lowestCount = counts[0]\n","midLabel,midCount = counts[1]\n","highLabel,highCount = counts[2]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KFu3RHoGwNZl","colab_type":"code","colab":{}},"source":["df_low_upscaled = df.filter(df.label==lowestLabel).sample(withReplacement=True,fraction = highCount/lowestCount)\n","df_mid_upscaled = df.filter(df.label==midLabel).sample(withReplacement=True,fraction = highCount/midCount)\n","df_high_upscaled = df.filter(df.label==highLabel)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkR_isB0wNZr","colab_type":"code","colab":{}},"source":["from functools import reduce\n","from pyspark.sql import DataFrame\n","dfs_labelwise = [df_low_upscaled,df_mid_upscaled,df_high_upscaled]\n","df_balanced = reduce(DataFrame.unionAll, dfs_labelwise)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-Nw07WpwNZw","colab_type":"code","colab":{},"outputId":"2c99f8dc-e341-4374-f9c5-7a2146f96ba8"},"source":["df_balanced.printSchema()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["root\n"," |-- claim: string (nullable = true)\n"," |-- claimant: string (nullable = true)\n"," |-- articles: string (nullable = true)\n"," |-- label: integer (nullable = true)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gBseUphiwNZ2","colab_type":"code","colab":{},"outputId":"43858edf-35f7-443e-f7d6-b2db67fe2041"},"source":["df_balanced.count()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22302"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"y6FdEj0PwNZ7","colab_type":"code","colab":{},"outputId":"c826a87d-7398-4e8d-e4b6-f527e394dcf0"},"source":["counts = df_balanced.select('label').groupBy('label').count().orderBy('count').collect()\n","counts"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(label=1, count=7396), Row(label=0, count=7408), Row(label=2, count=7498)]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"D9dRMkj4wNZ_","colab_type":"code","colab":{}},"source":["from pyspark.ml.feature import Tokenizer,StopWordsRemover,CountVectorizer,IDF,VectorAssembler,Word2Vec,MinMaxScaler#,StringIndexer\n","from pyspark.ml import Pipeline\n","\n","tokenizer = Tokenizer(inputCol='articles',outputCol='token_text')\n","stop_remove = StopWordsRemover(inputCol='token_text',outputCol='stop_token')\n","word2vec = Word2Vec (inputCol='stop_token',outputCol = \"word_2_vec\")\n","mms = MinMaxScaler(inputCol = 'word_2_vec',outputCol = \"scaled\")\n","assembler = VectorAssembler(inputCols=['scaled'],outputCol='features')\n","\n","pipe = Pipeline(stages=[tokenizer,stop_remove,word2vec,mms,assembler])\n","pipelineFit = pipe.fit(df_balanced)\n","dataset = pipelineFit.transform(df_balanced)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S329UgCcwNaF","colab_type":"code","colab":{}},"source":["training,test = dataset.randomSplit(weights = [0.8,0.2],seed = 0 )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2VP7GmtwNaJ","colab_type":"code","colab":{}},"source":["from pyspark.ml.tuning import ParamGridBuilder,CrossValidator\n","from pyspark.ml.classification import NaiveBayes\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","nb = NaiveBayes()\n","\n","gridSearch = ParamGridBuilder().addGrid(nb.smoothing,[0.0,0.2,0.4,0.6,0.8,1.0]).build()\n","cvEvaluater = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\",predictionCol=\"prediction\")\n","\n","cv = CrossValidator(estimator=nb,estimatorParamMaps=gridSearch,evaluator=cvEvaluater)\n","cvModel = cv.fit(training)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EwgdFomJwNaM","colab_type":"code","colab":{},"outputId":"6e7caf09-2056-4582-8826-7ac439cfb3b6"},"source":["cvModel.avgMetrics"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.4281263926545419,\n"," 0.4281263926545419,\n"," 0.4281263926545419,\n"," 0.42825432472492053,\n"," 0.42827508975918016,\n"," 0.4282040830891455]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"XUtoPueewNaQ","colab_type":"code","colab":{},"outputId":"4677abd3-b9d2-4fa1-a939-71559e7a279b"},"source":["from sklearn.metrics import classification_report\n","prediction = cvModel.transform(test)\n","y_true = prediction.select('label').collect()\n","y_pred = prediction.select('prediction').collect()\n","print (classification_report(y_true,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.44      0.57      0.50      1438\n","           1       0.46      0.45      0.45      1488\n","           2       0.41      0.30      0.35      1480\n","\n","    accuracy                           0.44      4406\n","   macro avg       0.44      0.44      0.43      4406\n","weighted avg       0.44      0.44      0.43      4406\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aUR4ppNwwNaU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}