{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"ARC-NN-CV-W2Vec-Unbalanced.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"xvqYYm6lpijG","colab_type":"code","colab":{},"outputId":"e863c176-15ec-4d49-f3da-9d222d26bf54"},"source":["import os\n","import atexit\n","import sys\n","\n","import pyspark\n","from pyspark.context import SparkContext\n","from pyspark.sql import SQLContext\n","import findspark\n","from sparkhpc import sparkjob\n","\n","#Exit handler to clean up the Spark cluster if the script exits or crashes\n","def exitHandler(sj,sc):\n","    try:\n","        print('Trapped Exit cleaning up Spark Context')\n","        sc.stop()\n","    except:\n","        pass\n","    try:\n","        print('Trapped Exit cleaning up Spark Job')\n","        sj.stop()\n","    except:\n","        pass\n","\n","findspark.init()\n","\n","#Parameters for the Spark cluster\n","nodes=3\n","tasks_per_node=12\n","memory_per_task=1536 #1.5 gig per process, adjust accordingly\n","# Please estimate walltime carefully to keep unused Spark clusters from sitting \n","# idle so that others may use the resources.\n","walltime=\"24:00\" #24 hour\n","os.environ['SBATCH_PARTITION']='parallel' #Set the appropriate ARC partition\n","\n","sj = sparkjob.sparkjob(\n","     ncores=nodes*tasks_per_node,\n","     cores_per_executor=tasks_per_node,\n","     memory_per_core=memory_per_task,\n","     walltime=walltime\n","    )\n","\n","sj.wait_to_start()\n","sc = sj.start_spark()\n","\n","#Register the exit handler                                                                                                     \n","atexit.register(exitHandler,sj,sc)\n","\n","#You need this line if you want to use SparkSQL\n","sqlCtx=SQLContext(sc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:sparkhpc.sparkjob:Submitted batch job 2627228\n","\n","INFO:sparkhpc.sparkjob:Submitted cluster 1\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FA2e75M9pijl","colab_type":"code","colab":{},"outputId":"53798ddc-ed51-4c72-f833-f45559b60be8"},"source":["news_data = sqlCtx.read.csv('Fake News Data set.csv',inferSchema=True)\n","news_data.printSchema()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["root\n"," |-- _c0: string (nullable = true)\n"," |-- _c1: string (nullable = true)\n"," |-- _c2: string (nullable = true)\n"," |-- _c3: integer (nullable = true)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ihczuI80pikC","colab_type":"code","colab":{},"outputId":"37441492-39cf-4118-d3be-75dfaefc9b08"},"source":["news_data = news_data.withColumnRenamed('_c0','claim').withColumnRenamed('_c1','claimant').withColumnRenamed('_c2','article_content').withColumnRenamed('_c3','label')\n","news_data.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+--------------------+-----------------+--------------------+-----+\n","|               claim|         claimant|     article_content|label|\n","+--------------------+-----------------+--------------------+-----+\n","|a line from georg...|             null|1984 george orwel...|    0|\n","|maine legislature...|             null|republican who cr...|    2|\n","|a 17yearold girl ...|             null|first person to c...|    1|\n","|in 1988 author ro...|             null|how dangerous is ...|    2|\n","|when it comes to ...|  Hillary Clinton|remarks on counte...|    2|\n","|rhode island is a...|Leonidas Raptakis|lis  code of virg...|    2|\n","|the poorest count...|         Jim Webb|counties in appal...|    1|\n","|koch industries p...|             null|update confrontin...|    0|\n","|minnesota michiga...|        Robin Vos|robin vos discuss...|    1|\n","|fbi uniform crime...|     Nick Schroer|fbi over four tim...|    1|\n","|pelosi sinks to n...|  Western Journal|pelosi sinks to n...|    0|\n","|socialist teacher...|             null|r wolfe on twitte...|    1|\n","|says that in the ...|   Jonathan Saenz|0418 jblancpftexa...|    1|\n","|nasa has just con...|         Bloggers|another moon for ...|    0|\n","|we are always goi...|      Mike Parson|seg 1 missouri go...|    2|\n","|justin amash is r...|     Justin Amash|elections electio...|    0|\n","|breaking nfl owne...|Multiple websites|statement from nf...|    0|\n","|says one year ago...|       Greg Casar|current sick days...|    0|\n","|says north caroli...|       Kay  Hagan|radio ad tillis m...|    1|\n","|says the mandate ...|     Jason Conger|oregon house appr...|    0|\n","+--------------------+-----------------+--------------------+-----+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s279pWvHpikQ","colab_type":"code","colab":{}},"source":["from pyspark.ml import Pipeline \n","from pyspark.ml.feature import Word2Vec, Tokenizer, VectorAssembler, StopWordsRemover ,MinMaxScaler\n","\n","tokenize = Tokenizer(inputCol = 'article_content', outputCol='tokenized')\n","stopwrd = StopWordsRemover(inputCol='tokenized',outputCol='cleaned')\n","w2vec = Word2Vec(inputCol='cleaned',outputCol='mnmx')\n","#minmax = MinMaxScaler(inputCol = 'mnmx',outputCol = 'scaled')\n","assembler = VectorAssembler(inputCols=['mnmx'],outputCol='features')\n","\n","pipe = Pipeline(stages=[tokenize,stopwrd,w2vec,assembler])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TDslLA6lpikV","colab_type":"code","colab":{}},"source":["pipelineFit_1 = pipe.fit(news_data)\n","dataset_1 = pipelineFit_1.transform(news_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMq3DiN6pilj","colab_type":"code","colab":{}},"source":["training, test = dataset_1.randomSplit(weights=[0.8,0.2],seed=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VGQlCguRpilz","colab_type":"code","colab":{}},"source":["from pyspark.ml.classification import MultilayerPerceptronClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","input_layers = len(training.select('features').take(1)[0].asDict()['features'])\n","output_classes = 3\n","layers = [input_layers, 128, 128, output_classes]\n","\n","trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n","\n","train_model = trainer.fit(training)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kUo4oFK_pil2","colab_type":"code","colab":{},"outputId":"6b5987da-de58-4d8a-b6b7-fdaffd469fde"},"source":["from sklearn.metrics import classification_report\n","\n","prediction = train_model.transform(test)\n","\n","y_true = prediction.select('label').collect()\n","y_pred = prediction.select('prediction').collect()\n","\n","print(classification_report(y_true,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.71      0.68      1477\n","           1       0.58      0.66      0.62      1287\n","           2       0.40      0.01      0.01       294\n","\n","    accuracy                           0.62      3058\n","   macro avg       0.54      0.46      0.44      3058\n","weighted avg       0.60      0.62      0.59      3058\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GXFXoXPgpil8","colab_type":"code","colab":{}},"source":["input_layers_1 = len(training.select('features').take(1)[0].asDict()['features'])\n","output_classes_1 = 3\n","layers_1 = [input_layers_1, 256, 256, output_classes_1]\n","\n","trainer_1 = MultilayerPerceptronClassifier(maxIter=100, layers=layers_1, blockSize=128, seed=1234)\n","\n","train_model_1 = trainer_1.fit(training)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YkGCGdo2pil-","colab_type":"code","colab":{},"outputId":"882688bf-1af8-4783-f0c1-4e5f54b107ce"},"source":["from sklearn.metrics import classification_report\n","\n","prediction_1 = train_model_1.transform(test)\n","\n","y_true_1 = prediction_1.select('label').collect()\n","y_pred_1 = prediction_1.select('prediction').collect()\n","\n","print(classification_report(y_true_1,y_pred_1))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.71      0.67      1477\n","           1       0.58      0.64      0.61      1287\n","           2       0.00      0.00      0.00       294\n","\n","    accuracy                           0.61      3058\n","   macro avg       0.41      0.45      0.43      3058\n","weighted avg       0.55      0.61      0.58      3058\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/global/software/jupyterhub-spark/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_M2b53BBpimA","colab_type":"code","colab":{}},"source":["input_layers = len(training.select('features').take(1)[0].asDict()['features'])\n","output_classes = 3\n","layers_2 = [input_layers, 128, 128, 128,output_classes]\n","\n","trainer_2 = MultilayerPerceptronClassifier(maxIter=100, layers=layers_2, blockSize=128, seed=1234)\n","\n","train_model_2 = trainer_2.fit(training)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MXc_DDu6pimD","colab_type":"code","colab":{},"outputId":"bf960534-b763-4333-be93-5b8ed5a2f20c"},"source":["from sklearn.metrics import classification_report\n","\n","prediction_2 = train_model_2.transform(test)\n","\n","y_true_2 = prediction_2.select('label').collect()\n","y_pred_2 = prediction_2.select('prediction').collect()\n","\n","print(classification_report(y_true_2,y_pred_2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.70      0.67      1477\n","           1       0.57      0.64      0.60      1287\n","           2       0.00      0.00      0.00       294\n","\n","    accuracy                           0.61      3058\n","   macro avg       0.40      0.45      0.42      3058\n","weighted avg       0.55      0.61      0.58      3058\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/global/software/jupyterhub-spark/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zajZFrY7pimG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}